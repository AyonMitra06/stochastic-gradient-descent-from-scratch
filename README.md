# stochastic-gradient-descent-from-scratch
Stochastic Gradient Descent from Scratch involves manually implementing the SGD algorithm to train a linear regression model by updating the weights using one randomly selected data point at a time. This helps in understanding how gradients, learning rate, and randomness affect model learning.
